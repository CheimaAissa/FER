{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport argparse\nimport errno\nimport dlib\nimport cv2\nimport imageio","metadata":{"execution":{"iopub.status.busy":"2022-12-25T21:35:11.754438Z","iopub.execute_input":"2022-12-25T21:35:11.755108Z","iopub.status.idle":"2022-12-25T21:35:12.169699Z","shell.execute_reply.started":"2022-12-25T21:35:11.755022Z","shell.execute_reply":"2022-12-25T21:35:12.168725Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"image_height = 48\nimage_width = 48\nwindow_size = 24\nwindow_step = 6\nSELECTED_LABELS = [0,1,2,3,4,5,6]\n#IMAGES_PER_LABEL = 500\nOUTPUT_FOLDER_NAME = \"fer2013_features\"","metadata":{"execution":{"iopub.status.busy":"2022-12-25T21:35:14.044245Z","iopub.execute_input":"2022-12-25T21:35:14.044633Z","iopub.status.idle":"2022-12-25T21:35:14.051614Z","shell.execute_reply.started":"2022-12-25T21:35:14.044600Z","shell.execute_reply":"2022-12-25T21:35:14.049555Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"predictor = dlib.shape_predictor('/kaggle/input/shape-predictor-68-face-landmarksdat/shape_predictor_68_face_landmarks.dat')\noriginal_labels = [0, 1, 2, 3, 4, 5, 6]\nnew_labels = list(set(original_labels) & set(SELECTED_LABELS))\nnb_images_per_label = list(np.zeros(len(SELECTED_LABELS), 'uint8'))\ntry:\n    os.makedirs(OUTPUT_FOLDER_NAME)\nexcept OSError as e:\n    if e.errno == errno.EEXIST and os.path.isdir(OUTPUT_FOLDER_NAME):\n        pass\n    else:\n        raise","metadata":{"execution":{"iopub.status.busy":"2022-12-25T21:35:16.426780Z","iopub.execute_input":"2022-12-25T21:35:16.427158Z","iopub.status.idle":"2022-12-25T21:35:17.900430Z","shell.execute_reply.started":"2022-12-25T21:35:16.427125Z","shell.execute_reply":"2022-12-25T21:35:17.899283Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def get_landmarks(image, rects):\n    if len(rects) > 1:\n        raise BaseException(\"TooManyFaces\")\n    if len(rects) == 0:\n        raise BaseException(\"NoFaces\")\n    return np.matrix([[p.x, p.y] for p in predictor(image, rects[0]).parts()])\n\ndef get_new_label(label):\n    new_label = new_labels.index(label)\n    label = list(np.zeros(len(new_labels), 'uint8'))\n    label[new_label] = 1\n    return label\n\n'''def sliding_hog_windows(image):\n    hog_windows = []\n    for y in range(0, image_height, window_step):\n        for x in range(0, image_width, window_step):\n            window = image[y:y+window_size, x:x+window_size]\n            hog_windows.extend(hog(window, orientations=8, pixels_per_cell=(8, 8),\n                                            cells_per_block=(1, 1), visualise=False))\n    return hog_windows'''","metadata":{"execution":{"iopub.status.busy":"2022-12-25T21:35:22.647907Z","iopub.execute_input":"2022-12-25T21:35:22.648255Z","iopub.status.idle":"2022-12-25T21:35:22.657611Z","shell.execute_reply.started":"2022-12-25T21:35:22.648226Z","shell.execute_reply":"2022-12-25T21:35:22.656430Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"'def sliding_hog_windows(image):\\n    hog_windows = []\\n    for y in range(0, image_height, window_step):\\n        for x in range(0, image_width, window_step):\\n            window = image[y:y+window_size, x:x+window_size]\\n            hog_windows.extend(hog(window, orientations=8, pixels_per_cell=(8, 8),\\n                                            cells_per_block=(1, 1), visualise=False))\\n    return hog_windows'"},"metadata":{}}]},{"cell_type":"code","source":"print( \"importing csv file\")\ndata = pd.read_csv('/kaggle/input/fer2013/fer2013.csv')\n\nfor category in data['Usage'].unique():\n    print( \"converting set: \" + category + \"...\")\n    # create folder\n    if not os.path.exists(category):\n        try:\n            os.makedirs(OUTPUT_FOLDER_NAME + '/' + category)\n        except OSError as e:\n            if e.errno == errno.EEXIST and os.path.isdir(OUTPUT_FOLDER_NAME):\n                pass\n            else:\n                raise\n    category_data = data[data['Usage'] == category]\n    samples = category_data['pixels'].values\n    labels = category_data['emotion'].values\n    images = []\n    landmarks = []\n    labels_list = []\n    print(category)\n    print(len(samples))\n    for i in range(len(samples)):\n        try:\n            if labels[i] in SELECTED_LABELS :\n                image = np.fromstring(samples[i], dtype=int, sep=\" \").reshape((image_height, image_width))\n                images.append(image)\n                imageio.imwrite('temp.jpg', image)\n                image2 = cv2.imread('temp.jpg')\n                face_rects = [dlib.rectangle(left=1, top=1, right=47, bottom=47)]\n                face_landmarks = get_landmarks(image2, face_rects)\n                landmarks.append(face_landmarks)       \n                labels_list.append(get_new_label(labels[i]))\n        except Exception as e:\n            print( \"error in image: \" + str(i) + \" - \" + str(e))\n    np.save(OUTPUT_FOLDER_NAME + '/' + category + '/images.npy', images)\n    print(\"done\")\n    np.save(OUTPUT_FOLDER_NAME + '/' + category + '/landmarks.npy', landmarks)\n    print(\"done\")\n    np.save(OUTPUT_FOLDER_NAME + '/' + category + '/labels.npy', labels_list)\n    print(\"done\")","metadata":{"execution":{"iopub.status.busy":"2022-12-25T21:35:28.023571Z","iopub.execute_input":"2022-12-25T21:35:28.023932Z","iopub.status.idle":"2022-12-25T21:37:19.380130Z","shell.execute_reply.started":"2022-12-25T21:35:28.023901Z","shell.execute_reply":"2022-12-25T21:37:19.378969Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"importing csv file\nconverting set: Training...\nTraining\n28709\ndone\ndone\ndone\nconverting set: PublicTest...\nPublicTest\n3589\ndone\ndone\ndone\nconverting set: PrivateTest...\nPrivateTest\n3589\ndone\ndone\ndone\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\n\nclass Dataset:\n    name = 'Fer2013'\n    train_folder = 'fer2013_features/Training'\n    validation_folder = 'fer2013_features/PublicTest'\n    test_folder = 'fer2013_features/PrivateTest'\n    shape_predictor_path='/kaggle/input/shape-predictor-68-face-landmarksdat/shape_predictor_68_face_landmarks.dat'\n\nclass Network:\n    model = 'B'\n    input_size = 48\n    output_size = 7\n    activation = 'relu'\n    loss = 'categorical_crossentropy'   \n    use_batchnorm_after_conv_layers = True\n\nclass Hyperparams:\n    keep_prob = 0.956   # dropout = 1 - keep_prob\n    learning_rate = 0.016\n    learning_rate_decay = 0.864\n    decay_step = 50\n    optimizer = 'adam'  # {'momentum', 'adam', 'rmsprop', 'adagrad', 'adadelta'}\n    optimizer_param = 1   # momentum value for Momentum optimizer, or beta1 value for Adam\n\nclass Training:\n    batch_size = 128\n    epochs = 13\n    snapshot_step = 500\n    vizualize = True\n    logs_dir = \"logs\"\n    checkpoint_dir = \"checkpoints/chk\"\n    best_checkpoint_path = \"checkpoints/best/\"\n    max_checkpoints = 1\n    checkpoint_frequency = 1.0 # in hours\n    save_model = True\n    save_model_path = \"best_model/saved_model.bin\"\n\nclass VideoPredictor:\n    emotions = [\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\", \"Neutral\"]\n    print_emotions = False\n    camera_source = 0\n    face_detection_classifier = \"lbpcascade_frontalface.xml\"\n    show_confidence = False\n    time_to_wait_between_predictions = 0.5\n\nclass OptimizerSearchSpace:\n    learning_rate = {'min': 0.00001, 'max': 0.1}\n    learning_rate_decay = {'min': 0.5, 'max': 0.99}\n    optimizer = ['adam']   # ['momentum', 'adam', 'rmsprop', 'adagrad', 'adadelta']\n    optimizer_param = {'min': 0.5, 'max': 0.99}\n    keep_prob = {'min': 0.7, 'max': 0.99}\n\ndef make_dir(folder):\n    if not os.path.exists(folder):\n        os.makedirs(folder)\n\nDATASET = Dataset()\nNETWORK = Network()\nTRAINING = Training()\nHYPERPARAMS = Hyperparams()\nVIDEO_PREDICTOR = VideoPredictor()\nOPTIMIZER = OptimizerSearchSpace()\n\nmake_dir(TRAINING.logs_dir)\nmake_dir(TRAINING.checkpoint_dir)","metadata":{"execution":{"iopub.status.busy":"2022-12-25T21:37:23.956350Z","iopub.execute_input":"2022-12-25T21:37:23.957478Z","iopub.status.idle":"2022-12-25T21:37:23.970214Z","shell.execute_reply.started":"2022-12-25T21:37:23.957436Z","shell.execute_reply":"2022-12-25T21:37:23.968967Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\ndef load_data(validation=False, test=False):\n    \n    data_dict = dict()\n    validation_dict = dict()\n    test_dict = dict()\n\n    if DATASET.name == \"Fer2013\":\n\n        # load train set\n        data_dict['X'] = np.load(\"/kaggle/working/fer2013_features/Training/images.npy\")\n        data_dict['X'] = data_dict['X'].reshape([-1, NETWORK.input_size, NETWORK.input_size, 1])\n        data_dict['X2'] = np.load(\"/kaggle/working/fer2013_features/Training/landmarks.npy\")\n        data_dict['Y'] = np.load(\"/kaggle/working/fer2013_features/Training/labels.npy\")\n\n        if validation:\n            # load validation set\n            validation_dict['X'] = np.load(\"/kaggle/working/fer2013_features/PublicTest/images.npy\")\n            validation_dict['X'] = validation_dict['X'].reshape([-1, NETWORK.input_size, NETWORK.input_size, 1])\n            validation_dict['X2'] = np.load(\"/kaggle/working/fer2013_features/PublicTest/landmarks.npy\")\n            validation_dict['Y'] = np.load(\"/kaggle/working/fer2013_features/PublicTest/labels.npy\")\n        \n        if test:\n            # load test set\n            test_dict['X'] = np.load(\"/kaggle/working/fer2013_features/PrivateTest/images.npy\")\n            test_dict['X'] = test_dict['X'].reshape([-1, NETWORK.input_size, NETWORK.input_size, 1])\n            test_dict['X2'] = np.load(\"/kaggle/working/fer2013_features/PrivateTest/landmarks.npy\")\n            test_dict['Y'] = np.load(\"/kaggle/working/fer2013_features/PrivateTest/labels.npy\")\n    \n        if not validation and not test:\n            return data_dict\n        elif not test:\n            return data_dict, validation_dict\n        else: \n            return data_dict, validation_dict, test_dict\n    else:\n        print( \"Unknown dataset\")\n        exit()","metadata":{"execution":{"iopub.status.busy":"2022-12-25T21:37:28.690685Z","iopub.execute_input":"2022-12-25T21:37:28.691046Z","iopub.status.idle":"2022-12-25T21:37:28.702102Z","shell.execute_reply.started":"2022-12-25T21:37:28.691016Z","shell.execute_reply":"2022-12-25T21:37:28.701024Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"!pip install tflearn","metadata":{"execution":{"iopub.status.busy":"2022-12-25T21:37:32.038957Z","iopub.execute_input":"2022-12-25T21:37:32.040063Z","iopub.status.idle":"2022-12-25T21:37:45.546717Z","shell.execute_reply.started":"2022-12-25T21:37:32.040015Z","shell.execute_reply":"2022-12-25T21:37:45.545489Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Collecting tflearn\n  Downloading tflearn-0.5.0.tar.gz (107 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.3/107.3 kB\u001b[0m \u001b[31m542.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from tflearn) (1.21.6)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from tflearn) (1.15.0)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.7/site-packages (from tflearn) (9.1.1)\nBuilding wheels for collected packages: tflearn\n  Building wheel for tflearn (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for tflearn: filename=tflearn-0.5.0-py3-none-any.whl size=127299 sha256=a10e355ee0fd27a38f4eb50f13ee27b43f3d93bb399469570ed685cda15998e5\n  Stored in directory: /root/.cache/pip/wheels/5f/14/2e/1d8e28cc47a5a931a2fb82438c9e37ef9246cc6a3774520271\nSuccessfully built tflearn\nInstalling collected packages: tflearn\nSuccessfully installed tflearn-0.5.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf \nfrom tflearn.layers.core import input_data, dropout, fully_connected\nfrom tflearn.layers.conv import conv_2d, max_pool_2d\nfrom tflearn.layers.merge_ops import merge_outputs, merge\nfrom tflearn.layers.normalization import local_response_normalization, batch_normalization\nfrom tflearn.layers.estimator import regression \nfrom tflearn.optimizers import Momentum, Adam","metadata":{"execution":{"iopub.status.busy":"2022-12-25T21:37:46.786409Z","iopub.execute_input":"2022-12-25T21:37:46.787363Z","iopub.status.idle":"2022-12-25T21:37:51.129606Z","shell.execute_reply.started":"2022-12-25T21:37:46.787325Z","shell.execute_reply":"2022-12-25T21:37:51.128648Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def build_model(optimizer=HYPERPARAMS.optimizer, optimizer_param=HYPERPARAMS.optimizer_param, \n    learning_rate=HYPERPARAMS.learning_rate, keep_prob=HYPERPARAMS.keep_prob,\n    learning_rate_decay=HYPERPARAMS.learning_rate_decay, decay_step=HYPERPARAMS.decay_step):\n\n    images_network = input_data(shape=[None, NETWORK.input_size, NETWORK.input_size, 1], name='input1')\n    images_network = conv_2d(images_network, 64, 3, activation=NETWORK.activation)\n    images_network = batch_normalization(images_network)\n    images_network = max_pool_2d(images_network, 3, strides = 2)\n    images_network = conv_2d(images_network, 128, 3, activation=NETWORK.activation)\n    \n    images_network = batch_normalization(images_network)\n    images_network = max_pool_2d(images_network, 3, strides = 2)\n    images_network = conv_2d(images_network, 256, 3, activation=NETWORK.activation)\n    \n    images_network = batch_normalization(images_network)\n    images_network = max_pool_2d(images_network, 3, strides = 2)\n    images_network = dropout(images_network, keep_prob=keep_prob)\n    images_network = fully_connected(images_network, 4096, activation=NETWORK.activation)\n    images_network = dropout(images_network, keep_prob=keep_prob)\n    images_network = fully_connected(images_network, 1024, activation=NETWORK.activation)\n    landmarks_network = input_data(shape=[None, 68, 2], name='input2')\n    landmarks_network = fully_connected(landmarks_network, 1024, activation=NETWORK.activation)\n    landmarks_network = fully_connected(landmarks_network, 128, activation=NETWORK.activation)\n    images_network = fully_connected(images_network, 128, activation=NETWORK.activation)\n    network = merge([images_network, landmarks_network], 'concat', axis=1)\n    network = fully_connected(network,NETWORK.output_size, activation='softmax')\n    optimizer = Adam(learning_rate=learning_rate, beta1=optimizer_param, beta2=learning_rate_decay)\n    network = regression(network, optimizer=optimizer, loss=NETWORK.loss, learning_rate=learning_rate, name='output')\n\n    return network","metadata":{"execution":{"iopub.status.busy":"2022-12-25T21:37:53.979861Z","iopub.execute_input":"2022-12-25T21:37:53.980438Z","iopub.status.idle":"2022-12-25T21:37:53.994185Z","shell.execute_reply.started":"2022-12-25T21:37:53.980404Z","shell.execute_reply":"2022-12-25T21:37:53.993000Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"'''def build_model(optimizer=HYPERPARAMS.optimizer, optimizer_param=HYPERPARAMS.optimizer_param, \n    learning_rate=HYPERPARAMS.learning_rate, keep_prob=HYPERPARAMS.keep_prob,\n    learning_rate_decay=HYPERPARAMS.learning_rate_decay, decay_step=HYPERPARAMS.decay_step):\n\n    images_network = input_data(shape=[None, NETWORK.input_size, NETWORK.input_size, 1], name='input1')\n    images_network = conv_2d(images_network, 64, 5, activation=NETWORK.activation)     \n    images_network = batch_normalization(images_network)\n    images_network = max_pool_2d(images_network, 3, strides = 2)\n    images_network = conv_2d(images_network, 64, 5, activation=NETWORK.activation)\n    images_network = batch_normalization(images_network)\n    images_network = max_pool_2d(images_network, 3, strides = 2)\n    images_network = conv_2d(images_network, 128, 4, activation=NETWORK.activation)\n    images_network = batch_normalization(images_network)\n    images_network = dropout(images_network, keep_prob=keep_prob)\n    images_network = fully_connected(images_network, 1024, activation=NETWORK.activation) \n    landmarks_network = input_data(shape=[None, 68, 2], name='input2')\n    landmarks_network = fully_connected(landmarks_network, 1024, activation=NETWORK.activation)\n    landmarks_network = fully_connected(landmarks_network, 40, activation=NETWORK.activation)\n    images_network = fully_connected(images_network, 40, activation=NETWORK.activation)\n    network = merge([images_network, landmarks_network], 'concat', axis=1)\n    network = fully_connected(network, NETWORK.output_size, activation='softmax')\n    optimizer = Adam(learning_rate=learning_rate, beta1=optimizer_param, beta2=learning_rate_decay)\n    network = regression(network, optimizer=optimizer, loss=NETWORK.loss, learning_rate=learning_rate, name='output')\n\n    return network'''","metadata":{"execution":{"iopub.status.busy":"2022-12-25T21:25:25.425965Z","iopub.execute_input":"2022-12-25T21:25:25.426359Z","iopub.status.idle":"2022-12-25T21:25:25.439815Z","shell.execute_reply.started":"2022-12-25T21:25:25.426325Z","shell.execute_reply":"2022-12-25T21:25:25.438793Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tflearn import DNN\nimport time\nimport argparse\nimport os","metadata":{"execution":{"iopub.status.busy":"2022-12-25T21:38:03.215381Z","iopub.execute_input":"2022-12-25T21:38:03.216367Z","iopub.status.idle":"2022-12-25T21:38:03.223434Z","shell.execute_reply.started":"2022-12-25T21:38:03.216331Z","shell.execute_reply":"2022-12-25T21:38:03.222237Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def train(optimizer=HYPERPARAMS.optimizer, optimizer_param=HYPERPARAMS.optimizer_param, \n        learning_rate=HYPERPARAMS.learning_rate, keep_prob=HYPERPARAMS.keep_prob, \n        learning_rate_decay=HYPERPARAMS.learning_rate_decay, decay_step=HYPERPARAMS.decay_step,\n        train_model=True):\n\n        print( \"loading dataset \" + DATASET.name + \"...\")\n        if train_model:\n                data, validation = load_data(validation=True)\n        else:\n                data, validation, test = load_data(validation=True, test=True)\n\n        with tf.Graph().as_default():\n                print( \"building model...\")\n                network = build_model(optimizer, optimizer_param, learning_rate, \n                          keep_prob, learning_rate_decay, decay_step)\n                model = DNN(network, tensorboard_dir=TRAINING.logs_dir, \n                        tensorboard_verbose=0, checkpoint_path=TRAINING.checkpoint_dir,\n                        max_checkpoints=TRAINING.max_checkpoints)\n\n                #tflearn.config.init_graph(seed=None, log_device=False, num_cores=6)\n\n                if train_model:\n                        # Training phase\n                        print( \"start training...\")\n                        print( \"  - emotions = {}\".format(NETWORK.output_size))\n                        print( \"  - model = {}\".format(NETWORK.model))\n                        print( \"  - optimizer = '{}'\".format(optimizer))\n                        print( \"  - learning_rate = {}\".format(learning_rate))\n                        print( \"  - learning_rate_decay = {}\".format(learning_rate_decay))\n                        print( \"  - otimizer_param ({}) = {}\".format('beta1' if optimizer == 'adam' else 'momentum', optimizer_param))\n                        print( \"  - keep_prob = {}\".format(keep_prob))\n                        print( \"  - epochs = {}\".format(TRAINING.epochs))\n                        #print( \"  - use landmarks = {}\".format(NETWORK.use_landmarks))\n\n                        start_time = time.time()\n                        \n                        model.fit([data['X'], data['X2']], data['Y'],\n                                    validation_set=([validation['X'], validation['X2']], validation['Y']),\n                                    snapshot_step=TRAINING.snapshot_step,\n                                    show_metric=TRAINING.vizualize,\n                                    batch_size=TRAINING.batch_size,\n                                    n_epoch=TRAINING.epochs)\n            \n                        training_time = time.time() - start_time\n                        print( \"training time = {0:.1f} sec\".format(training_time))\n\n                        if TRAINING.save_model:\n                            print( \"saving model...\")\n                            model.save(TRAINING.save_model_path)\n                            if not(os.path.isfile(TRAINING.save_model_path)) and \\\n                                    os.path.isfile(TRAINING.save_model_path + \".meta\"):\n                                    os.rename(TRAINING.save_model_path + \".meta\", TRAINING.save_model_path)\n                        print( \"evaluating...\")\n                        validation_accuracy = evaluate(model, validation['X'], validation['X2'], validation['Y'])\n                        print( \"  - validation accuracy = {0:.1f}\".format(validation_accuracy*100))\n                        return validation_accuracy\n                else:\n                        # Testing phase : load saved model and evaluate on test dataset\n                        print( \"start evaluation...\")\n                        print( \"loading pretrained model...\")\n                        if os.path.isfile(TRAINING.save_model_path):\n                                model.load(TRAINING.save_model_path)\n                        else:\n                                print( \"Error: file '{}' not found\".format(TRAINING.save_model_path))\n                                exit()\n                        \n                        print( \"--\")\n                        print( \"Validation samples: {}\".format(len(validation['Y'])))\n                        print( \"Test samples: {}\".format(len(test['Y'])))\n                        print( \"--\")\n                        print( \"evaluating...\")\n                        start_time = time.time()\n                        validation_accuracy = evaluate(model, validation['X'], validation['X2'], validation['Y'])\n                        print( \"  - validation accuracy = {0:.1f}\".format(validation_accuracy*100))\n                        test_accuracy = evaluate(model, test['X'], test['X2'], test['Y'])\n                        print( \"  - test accuracy = {0:.1f}\".format(test_accuracy*100))\n                        print( \"  - evalution time = {0:.1f} sec\".format(time.time() - start_time))\n                        return test_accuracy\n               ","metadata":{"execution":{"iopub.status.busy":"2022-12-25T21:38:05.058000Z","iopub.execute_input":"2022-12-25T21:38:05.058343Z","iopub.status.idle":"2022-12-25T21:38:05.077096Z","shell.execute_reply.started":"2022-12-25T21:38:05.058312Z","shell.execute_reply":"2022-12-25T21:38:05.076085Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def evaluate(model, X, X2, Y):\n    accuracy = model.evaluate([X, X2], Y)\n    return accuracy[0]","metadata":{"execution":{"iopub.status.busy":"2022-12-25T21:38:10.584401Z","iopub.execute_input":"2022-12-25T21:38:10.585095Z","iopub.status.idle":"2022-12-25T21:38:10.589667Z","shell.execute_reply.started":"2022-12-25T21:38:10.585058Z","shell.execute_reply":"2022-12-25T21:38:10.588576Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"train()","metadata":{"execution":{"iopub.status.busy":"2022-12-25T21:38:18.131071Z","iopub.execute_input":"2022-12-25T21:38:18.131664Z","iopub.status.idle":"2022-12-25T21:41:32.502469Z","shell.execute_reply.started":"2022-12-25T21:38:18.131629Z","shell.execute_reply":"2022-12-25T21:41:32.501305Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Training Step: 2924  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 9.619s\n| Adam | epoch: 013 | loss: nan - acc: 0.1351 -- iter: 28672/28709\nTraining Step: 2925  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 10.665s\n| Adam | epoch: 013 | loss: nan - acc: 0.1349 | val_loss: nan - val_acc: 0.1301 -- iter: 28709/28709\n--\ntraining time = 187.9 sec\nsaving model...\nevaluating...\n  - validation accuracy = 13.0\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"0.13011981053218166"},"metadata":{}}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tflearn import DNN\nimport time\nimport numpy as np\nimport argparse\nimport dlib\nimport cv2\nimport os\nfrom skimage.feature import hog\n\ndef load_model():\n    model = None\n    with tf.Graph().as_default():\n        print( \"loading pretrained model...\")\n        network = build_model()\n        model = DNN(network)\n        if os.path.isfile(TRAINING.save_model_path):\n            model.load(TRAINING.save_model_path)\n        else:\n            print( \"Error: file '{}' not found\".format(TRAINING.save_model_path))\n    return model\n\ndef get_landmarks(image, rects, predictor):\n    # this function have been copied from http://bit.ly/2cj7Fpq\n    if len(rects) > 1:\n        raise TooManyFaces\n    if len(rects) == 0:\n        raise NoFaces\n    return np.matrix([[p.x, p.y] for p in predictor(image, rects[0]).parts()])\n","metadata":{"execution":{"iopub.status.busy":"2022-12-25T21:41:35.895066Z","iopub.execute_input":"2022-12-25T21:41:35.895458Z","iopub.status.idle":"2022-12-25T21:41:36.580573Z","shell.execute_reply.started":"2022-12-25T21:41:35.895427Z","shell.execute_reply":"2022-12-25T21:41:36.579571Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"model = load_model()\nimage = cv2.imread(\"/kaggle/input/d/msambare/fer2013/test/angry/PrivateTest_10131363.jpg\")\nimage.shape","metadata":{"execution":{"iopub.status.busy":"2022-12-25T21:41:40.590601Z","iopub.execute_input":"2022-12-25T21:41:40.591169Z","iopub.status.idle":"2022-12-25T21:41:42.786399Z","shell.execute_reply.started":"2022-12-25T21:41:40.591124Z","shell.execute_reply":"2022-12-25T21:41:42.785468Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"loading pretrained model...\n","output_type":"stream"},{"name":"stderr","text":"2022-12-25 21:41:40.845680: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-25 21:41:40.846550: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-25 21:41:40.847155: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-25 21:41:40.847787: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-25 21:41:40.848331: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-25 21:41:40.848755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n2022-12-25 21:41:41.937121: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-25 21:41:41.937875: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-25 21:41:41.938465: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-25 21:41:41.939006: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-25 21:41:41.939440: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-25 21:41:41.939818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n2022-12-25 21:41:42.000710: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-25 21:41:42.001230: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-25 21:41:42.001689: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-25 21:41:42.002169: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-25 21:41:42.002625: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-25 21:41:42.002981: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n2022-12-25 21:41:42.713730: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-25 21:41:42.714602: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-25 21:41:42.715174: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-25 21:41:42.715710: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-25 21:41:42.716178: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-25 21:41:42.716593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"(48, 48, 3)"},"metadata":{}}]},{"cell_type":"code","source":"def get_emotion(label):\n    if VIDEO_PREDICTOR.print_emotions:\n        print( \"- Angry: {0:.1f}%\\n- Happy: {1:.1f}%\\n- Sad: {2:.1f}%\\n- Surprise: {3:.1f}%\\n- Neutral: {4:.1f}%\".format(\n                label[0]*100, label[1]*100, label[2]*100, label[3]*100, label[4]*100))\n    label = label.tolist()\n    return VIDEO_PREDICTOR.emotions[label.index(max(label))],max(label)","metadata":{"execution":{"iopub.status.busy":"2022-12-25T21:41:45.336303Z","iopub.execute_input":"2022-12-25T21:41:45.336689Z","iopub.status.idle":"2022-12-25T21:41:45.345224Z","shell.execute_reply.started":"2022-12-25T21:41:45.336656Z","shell.execute_reply":"2022-12-25T21:41:45.343410Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"face_rects = [dlib.rectangle(left=0, top=0, right=NETWORK.input_size, bottom=NETWORK.input_size)]\nimage = cv2.imread(\"/kaggle/input/d/msambare/fer2013/train/angry/Training_10120469.jpg\")\nshape_predictor = dlib.shape_predictor(\"/kaggle/input/shape-predictor-68-face-landmarksdat/shape_predictor_68_face_landmarks.dat\")\nface_landmarks = np.array([get_landmarks(image, face_rects, shape_predictor)])\ntensor_image = image.reshape([-1, NETWORK.input_size, NETWORK.input_size, 1])","metadata":{"execution":{"iopub.status.busy":"2022-12-25T21:41:48.924374Z","iopub.execute_input":"2022-12-25T21:41:48.925413Z","iopub.status.idle":"2022-12-25T21:41:50.382741Z","shell.execute_reply.started":"2022-12-25T21:41:48.925376Z","shell.execute_reply":"2022-12-25T21:41:50.381741Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"tensor_image.shape","metadata":{"execution":{"iopub.status.busy":"2022-12-25T21:19:55.064234Z","iopub.execute_input":"2022-12-25T21:19:55.064925Z","iopub.status.idle":"2022-12-25T21:19:55.072805Z","shell.execute_reply.started":"2022-12-25T21:19:55.064887Z","shell.execute_reply":"2022-12-25T21:19:55.071720Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"(3, 48, 48, 1)"},"metadata":{}}]},{"cell_type":"code","source":"face_landmarks.shape","metadata":{"execution":{"iopub.status.busy":"2022-12-25T21:19:59.766136Z","iopub.execute_input":"2022-12-25T21:19:59.766540Z","iopub.status.idle":"2022-12-25T21:19:59.772851Z","shell.execute_reply.started":"2022-12-25T21:19:59.766503Z","shell.execute_reply":"2022-12-25T21:19:59.771739Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"(1, 68, 2)"},"metadata":{}}]},{"cell_type":"code","source":"predicted_label = model.predict([tensor_image,face_landmarks])","metadata":{"execution":{"iopub.status.busy":"2022-12-25T21:41:56.439788Z","iopub.execute_input":"2022-12-25T21:41:56.440360Z","iopub.status.idle":"2022-12-25T21:41:56.765930Z","shell.execute_reply.started":"2022-12-25T21:41:56.440317Z","shell.execute_reply":"2022-12-25T21:41:56.764466Z"},"trusted":true},"execution_count":21,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/3238510055.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredicted_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor_image\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mface_landmarks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: predict() got an unexpected keyword argument 'batch_size'"],"ename":"TypeError","evalue":"predict() got an unexpected keyword argument 'batch_size'","output_type":"error"}]},{"cell_type":"code","source":"emotion=get_emotion(predicted_label[0])\nprint( \"Prediction: {0} (confidence: {1:.1f}%)\".format(emotion, confidence*100))","metadata":{"execution":{"iopub.status.busy":"2022-12-25T13:35:53.342113Z","iopub.execute_input":"2022-12-25T13:35:53.342702Z","iopub.status.idle":"2022-12-25T13:35:53.376688Z","shell.execute_reply.started":"2022-12-25T13:35:53.342660Z","shell.execute_reply":"2022-12-25T13:35:53.373818Z"},"trusted":true},"execution_count":112,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/3388483931.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_emotion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'predicted_label' is not defined"],"ename":"NameError","evalue":"name 'predicted_label' is not defined","output_type":"error"}]}]}